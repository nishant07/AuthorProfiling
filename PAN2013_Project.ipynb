{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import nltk, sklearn\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahn\\Documents\\AuthorProfiling\\AuthorProfiling\n",
      "236600\n",
      "['ffffdf09a4c76ff65b6190e2f1050d7a_en_20s_male.xml', 'ffff40880ae891a0684ef963633c58a9_en_20s_male.xml', 'fffee4390614a689ba7f22e3844c63d3_en_20s_male.xml', 'fffeaa7d3162d6934a07ec4eb1f8f33e_en_20s_male.xml']\n"
     ]
    }
   ],
   "source": [
    "print os.getcwd()\n",
    "file_path = \"G:\\\\author profiling\\\\pan13-author-profiling-training-corpus-2013-01-09\\\\en\\\\\"\n",
    "#os.chdir(file_path)\n",
    "files = os.listdir(file_path)\n",
    "print len(files)\n",
    "print files[:-5:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPREHENSIVE SYNTACTIC CATEGORY  \n",
    "WTYPE: (**N**oun, ad**J**ective, **V**erb, **A**dverb, p**R**eposition,  \n",
    "**C**onjunction, prono**U**n, **I**nterjection, **P**ast participle, **O**ther)  \n",
    "CONTEXTUAL STATUS  \n",
    "STATUS: (Dollar= **S**pecialised, **A**rchaic, **C**apital, **D**ialect, nons**E**nse, **F**oreign/Alien, r**H**etorical, erro**N**eous, **O**bsolete,   **P**oetical, collo**Q**uial, **R**are, **S**tandard, nonce **W**ord )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NLET  POS    WORD CONTEXT\n",
      "0     5    S   &ARRY       N\n",
      "1     6    S  &CELLO       N\n",
      "2     2    S      &D       N\n",
      "3     3    Q     &EM       U\n",
      "4     4  NaN    &FLU       N\n",
      "Synset('move.n.01') noun.act\n",
      "Synset('move.n.02') noun.act\n",
      "Synset('motion.n.03') noun.act\n",
      "Synset('motion.n.06') noun.act\n",
      "Synset('move.n.05') noun.act\n",
      "Synset('travel.v.01') verb.motion\n",
      "Synset('move.v.02') verb.motion\n",
      "Synset('move.v.03') verb.motion\n",
      "Synset('move.v.04') verb.motion\n",
      "Synset('go.v.02') verb.social\n",
      "Synset('be_active.v.01') verb.body\n",
      "Synset('move.v.07') verb.change\n",
      "Synset('act.v.01') verb.social\n",
      "Synset('affect.v.05') verb.emotion\n",
      "Synset('motivate.v.01') verb.creation\n",
      "Synset('move.v.11') verb.emotion\n",
      "Synset('move.v.12') verb.possession\n",
      "Synset('move.v.13') verb.change\n",
      "Synset('move.v.14') verb.social\n",
      "Synset('move.v.15') verb.competition\n",
      "Synset('move.v.16') verb.communication\n"
     ]
    }
   ],
   "source": [
    "#Load MRC Data\n",
    "MRC = pd.read_csv(\"MRC Psycholinguistic Database\\\\MRC.csv\",na_values='')\n",
    "# COMPREHENSIVE SYNTACTIC CATEGORY\n",
    "# WTYPE: (Noun, adJective, Verb, Adverb, pReposition,\n",
    "# Conjunction, pronoUn, Interjection, Past participle, Other)\n",
    "# CONTEXTUAL STATUS\n",
    "# STATUS: ($ = Specialised, Archaic, Capital, Dialect, nonsEnse, Foreign/Alien, rHetorical, \n",
    "#          erroNeous, Obsolete, Poetical, colloQuial, Rare, Standard, nonce Word )\n",
    "print MRC.head()\n",
    "from nltk.corpus import wordnet as wn\n",
    "#Find Lexical info of tocken\n",
    "for synset in wn.synsets('move'):\n",
    "    print synset,synset.lexname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"..............................\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "c = 0\n",
    "fjson = open('PAN2013.json','w') \n",
    "fjson.write('{\"PAN2013\":[\\n')\n",
    "for file in files:\n",
    "    #print file\n",
    "    author = {}\n",
    "    author['file'] = file\n",
    "    with open(file_path+file,'r') as f:\n",
    "\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "#         print root.tag\n",
    "        #print root.attrib\n",
    "        author['gender'] = root.attrib['gender']\n",
    "        author['age'] = root.attrib['age_group']\n",
    "        #print gender, age\n",
    "        raw_text = []\n",
    "        for node in tree.iter('conversation'):\n",
    "            #print node.tag, node.attrib\n",
    "            #print node.text\n",
    "            try:\n",
    "                raw_text.append(BS(node.text, 'html.parser').get_text().strip())\n",
    "            except:\n",
    "                continue\n",
    "        author['raw_text'] = '\\n'.join(raw_text)\n",
    "        json.dump(author,fjson, indent = 4)\n",
    "        fjson.write(',\\n')\n",
    "        #print raw_text\n",
    "#         if c == 10:\n",
    "#             break\n",
    "    c+=1\n",
    "    #print c\n",
    "fjson.write('{} ]}\\n')\n",
    "fjson.close()\n",
    "#     with open(file,'r') as f:\n",
    "#         print f.readlines()\n",
    "#         for line in f.readlines():\n",
    "#             print line\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236600\n",
      "00851429b21722a4d62f63a328c601ca_en_20s_male\n"
     ]
    }
   ],
   "source": [
    "print c\n",
    "print files[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "c = 0\n",
    "for file in files:\n",
    "    #print file\n",
    "    author = {}\n",
    "    author['file'] = file\n",
    "    with open(file_path+file,'r') as f:\n",
    "        with open('G:\\\\author profiling\\\\PAN2013_Raw_JSON\\\\'+file[:-4]+'.json','w+') as fjson:\n",
    "            tree = ET.parse(f)\n",
    "            root = tree.getroot()\n",
    "    #         print root.tag\n",
    "            #print root.attrib\n",
    "            author['gender'] = root.attrib['gender']\n",
    "            author['age'] = root.attrib['age_group']\n",
    "            #print gender, age\n",
    "            raw_text = []\n",
    "            for node in tree.iter('conversation'):\n",
    "                #print node.tag, node.attrib\n",
    "                #print node.text\n",
    "                try:\n",
    "                    raw_text.append(BS(node.text, 'html.parser').get_text().strip())\n",
    "                except:\n",
    "                    continue\n",
    "            author['raw_text'] = '\\n'.join(raw_text)\n",
    "            json.dump(author,fjson, indent = 4)\n",
    "        #print raw_text\n",
    "    c+=1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
