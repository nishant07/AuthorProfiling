{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import nltk, sklearn\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blog2013_path = \"G:\\\\author profiling\\\\pan13-author-profiling-training-corpus-2013-01-09\\\\en\\\\\"\n",
    "blog2014_path = \"G:\\\\author profiling\\\\pan14-author-profiling-training-corpus-english-blogs-2014-04-16\\\\\"\n",
    "review2014_path = \"G:\\\\author profiling\\\\pan14-author-profiling-training-corpus-english-reviews-2014-04-16\\\\\"\n",
    "social2014_path = \"G:\\\\author profiling\\\\pan14-author-profiling-training-corpus-english-socialmedia-2014-04-16\\\\\"\n",
    "twitter2015_path = \"G:\\\\author profiling\\\\pan15-author-profiling-training-dataset-2015-04-23\\\\pan15-author-profiling-training-dataset-english-2015-04-23\\\\\"\n",
    "twitter2016_path = \"G:\\\\author profiling\\\\pan16-author-profiling-training-dataset-2016-04-25\\\\pan16-author-profiling-training-dataset-english-2016-04-25\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#files = os.listdir(file_path)\n",
    "blog2013_files = os.listdir(blog2013_path)\n",
    "blog2014_files = os.listdir(blog2014_path)\n",
    "review2014_files = os.listdir(review2014_path)\n",
    "social2014_files = os.listdir(social2014_path)\n",
    "twitter2015_files = os.listdir(twitter2015_path)\n",
    "twitter2016_files = os.listdir(twitter2016_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blog2013_files 200\n",
      "review2014_files 200\n",
      "review2014_files 200\n",
      "twitter2016_files 200\n"
     ]
    }
   ],
   "source": [
    "if len(blog2013_files)>200:\n",
    "    blog2013_files = np.random.choice(blog2013_files[:-1], 200)\n",
    "    print \"blog2013_files\",len(blog2013_files)\n",
    "else:\n",
    "    blog2013_files = blog2013_files[:-1]\n",
    "if len(blog2014_files)>200 :\n",
    "    blog2014_files = np.random.choice(blog2014_files[:-1], 200)\n",
    "    print \"blog2014_files\",len(blog2014_files)\n",
    "else:\n",
    "    blog2014_files = blog2014_files[:-1]\n",
    "if len(review2014_files)>200:\n",
    "    review2014_files = np.random.choice(review2014_files[:-1], 200)\n",
    "    print \"review2014_files\",len(review2014_files)\n",
    "else:\n",
    "    review2014_files = review2014_files[:-1]\n",
    "if len(social2014_files)>200:\n",
    "    social2014_files = np.random.choice(social2014_files[:-1], 200)\n",
    "    print \"review2014_files\", len(social2014_files)\n",
    "else:\n",
    "    social2014_files = social2014_files[:-1]\n",
    "if len(twitter2015_files)>200:\n",
    "    twitter2015_files = np.random.choice(twitter2015_files[:-1], 200)\n",
    "    print \"twitter2015_files\", len(twitter2015_files)\n",
    "else:\n",
    "    twitter2015_files = twitter2015_files[:-1]\n",
    "if len(twitter2016_files)>200:\n",
    "    twitter2016_files = np.random.choice(twitter2016_files[:-1], 200)\n",
    "    print \"twitter2016_files\", len(twitter2016_files)\n",
    "else:\n",
    "    twitter2016_files = twitter2016_files[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  Records processsed\n",
      "100  Records processsed\n",
      "150  Records processsed\n",
      "200  Records processsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female.xml</th>\n",
       "      <td>4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female...</td>\n",
       "      <td>Give and it wil come back to u.\\nbe comfortabl...</td>\n",
       "      <td>female</td>\n",
       "      <td>30s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84202b89d4b6bf136998efd49e3c976b_en_30s_female.xml</th>\n",
       "      <td>84202b89d4b6bf136998efd49e3c976b_en_30s_female...</td>\n",
       "      <td>Any affordable resort in London that is inside...</td>\n",
       "      <td>female</td>\n",
       "      <td>30s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml</th>\n",
       "      <td>3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml</td>\n",
       "      <td>Canines are among the most common sorts of pet...</td>\n",
       "      <td>male</td>\n",
       "      <td>30s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml</th>\n",
       "      <td>9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml</td>\n",
       "      <td>It is important to report your injury as soon ...</td>\n",
       "      <td>male</td>\n",
       "      <td>20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml</th>\n",
       "      <td>19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml</td>\n",
       "      <td>Decorating your home used to be really simple-...</td>\n",
       "      <td>male</td>\n",
       "      <td>30s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 file  \\\n",
       "4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female.xml  4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female...   \n",
       "84202b89d4b6bf136998efd49e3c976b_en_30s_female.xml  84202b89d4b6bf136998efd49e3c976b_en_30s_female...   \n",
       "3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml     3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml   \n",
       "9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml     9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml   \n",
       "19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml     19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female.xml  Give and it wil come back to u.\\nbe comfortabl...   \n",
       "84202b89d4b6bf136998efd49e3c976b_en_30s_female.xml  Any affordable resort in London that is inside...   \n",
       "3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml    Canines are among the most common sorts of pet...   \n",
       "9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml    It is important to report your injury as soon ...   \n",
       "19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml    Decorating your home used to be really simple-...   \n",
       "\n",
       "                                                    gender  age  \n",
       "4040cd1f2cdc51a847dfadfed9fb6e24_en_30s_female.xml  female  30s  \n",
       "84202b89d4b6bf136998efd49e3c976b_en_30s_female.xml  female  30s  \n",
       "3e6dafa50b26745648707ec61e8278d0_en_30s_male.xml      male  30s  \n",
       "9ba8b4c876ae609ec20d518de169dcfb_en_20s_male.xml      male  20s  \n",
       "19b9cdf91fa54461c2c344831f3da2be_en_30s_male.xml      male  30s  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "blog2013_df = pd.DataFrame(columns=('file', 'text', 'gender', 'age'))\n",
    "for file in blog2013_files:\n",
    "    #print file\n",
    "    author = {}\n",
    "    author['file'] = file\n",
    "    with open(blog2013_path+file,'r') as f:\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        author['gender'] = root.attrib['gender']\n",
    "        author['age'] = root.attrib['age_group']\n",
    "        #print gender, age\n",
    "        raw_text = []\n",
    "        for node in tree.iter('conversation'):\n",
    "            #print node.tag, node.attrib\n",
    "            #print node.text\n",
    "            try:\n",
    "                raw_text.append(BS(node.text, 'html.parser').get_text().strip())\n",
    "            except:\n",
    "                continue\n",
    "        author['text'] = '\\n'.join(raw_text)\n",
    "    author_series = pd.Series(author)\n",
    "    author_series.name = author['file']\n",
    "#     author_series =  pd.Series(dict(zip(['file', 'text', 'gender', 'age'], [author['file'],author['text'],author['gender'],author['age']])))\n",
    "    author_series.name = author['file']\n",
    "    blog2013_df = blog2013_df.append(author_series)\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print count,\" Records processsed\"\n",
    "blog2013_df.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  records processed\n",
      "100  records processed\n",
      "150  records processed\n",
      "200  records processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a11889bb92d6969286194525e90bfae1</th>\n",
       "      <td>a11889bb92d6969286194525e90bfae1</td>\n",
       "      <td>Excellent Hotel for the right traveller! I rea...</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccec4a7f232815502c8d8474bf76b95a</th>\n",
       "      <td>ccec4a7f232815502c8d8474bf76b95a</td>\n",
       "      <td>Loved the Mayfair Hotel/Location We returned l...</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>65-xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a089701a1d2b65589b209fff22bc512</th>\n",
       "      <td>3a089701a1d2b65589b209fff22bc512</td>\n",
       "      <td>Wonderful hotel! Can't beat Iberostar when it ...</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ccbc2d25d9c2095fbd8f85954954c12</th>\n",
       "      <td>2ccbc2d25d9c2095fbd8f85954954c12</td>\n",
       "      <td>For the most part,wonderful! We enjoyed Culebr...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>50-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4d392c7a6e253558c4068fa3ca121d76</th>\n",
       "      <td>4d392c7a6e253558c4068fa3ca121d76</td>\n",
       "      <td>I just don't get this hotel - So terrible I ju...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              file  \\\n",
       "a11889bb92d6969286194525e90bfae1  a11889bb92d6969286194525e90bfae1   \n",
       "ccec4a7f232815502c8d8474bf76b95a  ccec4a7f232815502c8d8474bf76b95a   \n",
       "3a089701a1d2b65589b209fff22bc512  3a089701a1d2b65589b209fff22bc512   \n",
       "2ccbc2d25d9c2095fbd8f85954954c12  2ccbc2d25d9c2095fbd8f85954954c12   \n",
       "4d392c7a6e253558c4068fa3ca121d76  4d392c7a6e253558c4068fa3ca121d76   \n",
       "\n",
       "                                                                               text  \\\n",
       "a11889bb92d6969286194525e90bfae1  Excellent Hotel for the right traveller! I rea...   \n",
       "ccec4a7f232815502c8d8474bf76b95a  Loved the Mayfair Hotel/Location We returned l...   \n",
       "3a089701a1d2b65589b209fff22bc512  Wonderful hotel! Can't beat Iberostar when it ...   \n",
       "2ccbc2d25d9c2095fbd8f85954954c12  For the most part,wonderful! We enjoyed Culebr...   \n",
       "4d392c7a6e253558c4068fa3ca121d76  I just don't get this hotel - So terrible I ju...   \n",
       "\n",
       "                                  gender    age  \n",
       "a11889bb92d6969286194525e90bfae1  FEMALE  35-49  \n",
       "ccec4a7f232815502c8d8474bf76b95a  FEMALE  65-xx  \n",
       "3a089701a1d2b65589b209fff22bc512  FEMALE  25-34  \n",
       "2ccbc2d25d9c2095fbd8f85954954c12    MALE  50-64  \n",
       "4d392c7a6e253558c4068fa3ca121d76    MALE  35-49  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review2014_path = \"G:\\\\author profiling\\\\pan14-author-profiling-training-corpus-english-reviews-2014-04-16\\\\\"\n",
    "truth_file = os.listdir(blog2014_path)[-1]\n",
    "reviews_truth_df = pd.read_csv(review2014_path+truth_file, sep=\":::\", header=None, names=('file','gender','age'))\n",
    "# print truth_df.columns.values\n",
    "reviews_truth_df = reviews_truth_df.set_index('file')\n",
    "review_df = pd.DataFrame(columns=('file', 'text', 'gender', 'age'))\n",
    "count = 0\n",
    "for file in review2014_files:\n",
    "    author = {}\n",
    "    author['file'] = file[:-4]\n",
    "    #print file\n",
    "    with open(review2014_path+file) as f:\n",
    "        tree = ET.parse(f)\n",
    "        raw_text = []        \n",
    "        for node in tree.iter('document'):\n",
    "            raw_text.append(BS(node.text, 'html.parser').get_text().strip())\n",
    "        author['text'] = '\\n'.join(raw_text)\n",
    "        author['gender'] = reviews_truth_df.loc[author['file']]['gender']\n",
    "        #print author['gender']\n",
    "        author['age'] = reviews_truth_df.loc[author['file']]['age']\n",
    "    author_series = pd.Series(author)\n",
    "    author_series.name = author['file']\n",
    "#     author_series =  pd.Series(dict(zip(['file', 'text', 'gender', 'age'], [author['file'],author['text'],author['gender'],author['age']])))\n",
    "    author_series.name = author['file']\n",
    "    review_df = review_df.append(author_series)\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print count,\" records processed\"\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  records processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.powerofpositivity.info/http://www.powerofpositivity.info/\n",
      "http://www.powerofpositivity.info/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  records processed\n",
      "150  records processed\n",
      "200  records processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429653a8ee0a1220cb5f0fa67c2705f</th>\n",
       "      <td>429653a8ee0a1220cb5f0fa67c2705f</td>\n",
       "      <td>iphone repair TorontoIf you need to have a new...</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e479736e602c1fc8bcc969b53ee37763</th>\n",
       "      <td>e479736e602c1fc8bcc969b53ee37763</td>\n",
       "      <td>On the internet Travel Portals - Generating Yo...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78dc1c79a97ad8772cc5d77e9fff676b</th>\n",
       "      <td>78dc1c79a97ad8772cc5d77e9fff676b</td>\n",
       "      <td>Starbucks to drop beetle juice from the menuSt...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3bb5355eac980b2c610dd5525d33e93c</th>\n",
       "      <td>3bb5355eac980b2c610dd5525d33e93c</td>\n",
       "      <td>homeopathy system of medicine explainedAs outl...</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349bd6c48993d6b6d5e88b91003baefe</th>\n",
       "      <td>349bd6c48993d6b6d5e88b91003baefe</td>\n",
       "      <td>Sexy test&gt; &gt; This is the SEXY test.&gt; &gt; Post th...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              file  \\\n",
       "429653a8ee0a1220cb5f0fa67c2705f    429653a8ee0a1220cb5f0fa67c2705f   \n",
       "e479736e602c1fc8bcc969b53ee37763  e479736e602c1fc8bcc969b53ee37763   \n",
       "78dc1c79a97ad8772cc5d77e9fff676b  78dc1c79a97ad8772cc5d77e9fff676b   \n",
       "3bb5355eac980b2c610dd5525d33e93c  3bb5355eac980b2c610dd5525d33e93c   \n",
       "349bd6c48993d6b6d5e88b91003baefe  349bd6c48993d6b6d5e88b91003baefe   \n",
       "\n",
       "                                                                               text  \\\n",
       "429653a8ee0a1220cb5f0fa67c2705f   iphone repair TorontoIf you need to have a new...   \n",
       "e479736e602c1fc8bcc969b53ee37763  On the internet Travel Portals - Generating Yo...   \n",
       "78dc1c79a97ad8772cc5d77e9fff676b  Starbucks to drop beetle juice from the menuSt...   \n",
       "3bb5355eac980b2c610dd5525d33e93c  homeopathy system of medicine explainedAs outl...   \n",
       "349bd6c48993d6b6d5e88b91003baefe  Sexy test> > This is the SEXY test.> > Post th...   \n",
       "\n",
       "                                  gender    age  \n",
       "429653a8ee0a1220cb5f0fa67c2705f   FEMALE  35-49  \n",
       "e479736e602c1fc8bcc969b53ee37763    MALE  18-24  \n",
       "78dc1c79a97ad8772cc5d77e9fff676b    MALE  25-34  \n",
       "3bb5355eac980b2c610dd5525d33e93c  FEMALE  18-24  \n",
       "349bd6c48993d6b6d5e88b91003baefe    MALE  18-24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#social2014_path = \"G:\\\\author profiling\\\\pan14-author-profiling-training-corpus-english-socialmedia-2014-04-16\\\\\"\n",
    "socialmedia_truth_df = pd.read_csv(social2014_path+os.listdir(social2014_path)[-1], sep=\":::\", header=None, names=('file','gender','age'))\n",
    "socialmedia_truth_df = socialmedia_truth_df.set_index('file')\n",
    "social_df = pd.DataFrame(columns=('file', 'text', 'gender', 'age'))\n",
    "count = 0\n",
    "for file in social2014_files:\n",
    "    author = {}\n",
    "    author['file'] = file[:-4]\n",
    "    #print file\n",
    "    with open(social2014_path+file) as f:\n",
    "        tree = ET.parse(f)\n",
    "        raw_text = []        \n",
    "        for node in tree.iter('document'):\n",
    "            raw_text.append(BS(BS(node.text, 'html.parser').get_text().strip(),'html.parser').get_text())            \n",
    "        author['text'] = '\\n'.join(raw_text)\n",
    "        author['gender'] = socialmedia_truth_df.loc[author['file']]['gender']\n",
    "        #print author['gender']\n",
    "        author['age'] = socialmedia_truth_df.loc[author['file']]['age']\n",
    "    author_series = pd.Series(author)\n",
    "    author_series.name = author['file']\n",
    "    social_df = social_df.append(author_series)\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print count, \" records processed\"\n",
    "social_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  records processed\n",
      "100  records processed\n",
      "150  records processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02ae95de-7ee3-453a-978d-25d28b3f1a88</th>\n",
       "      <td>02ae95de-7ee3-453a-978d-25d28b3f1a88</td>\n",
       "      <td>Things I want for my business cards but are to...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03f72f70-7a00-4dbb-93b7-6c7f65954fc5</th>\n",
       "      <td>03f72f70-7a00-4dbb-93b7-6c7f65954fc5</td>\n",
       "      <td>\"If you fight for a cause then fight for a cau...</td>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0aa7bace-924c-40fb-a2e5-3c7012ede244</th>\n",
       "      <td>0aa7bace-924c-40fb-a2e5-3c7012ede244</td>\n",
       "      <td>@username that tweet was mainly for you ;-) ch...</td>\n",
       "      <td>M</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b66092a-440e-4755-a624-759a580a1c70</th>\n",
       "      <td>0b66092a-440e-4755-a624-759a580a1c70</td>\n",
       "      <td>@username 'red' and 'blue' and then you wait t...</td>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094e809-1306-4cd1-8ac1-ebfdf7c872b8</th>\n",
       "      <td>1094e809-1306-4cd1-8ac1-ebfdf7c872b8</td>\n",
       "      <td>I sit with a boy in english he became my frien...</td>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      file  \\\n",
       "02ae95de-7ee3-453a-978d-25d28b3f1a88  02ae95de-7ee3-453a-978d-25d28b3f1a88   \n",
       "03f72f70-7a00-4dbb-93b7-6c7f65954fc5  03f72f70-7a00-4dbb-93b7-6c7f65954fc5   \n",
       "0aa7bace-924c-40fb-a2e5-3c7012ede244  0aa7bace-924c-40fb-a2e5-3c7012ede244   \n",
       "0b66092a-440e-4755-a624-759a580a1c70  0b66092a-440e-4755-a624-759a580a1c70   \n",
       "1094e809-1306-4cd1-8ac1-ebfdf7c872b8  1094e809-1306-4cd1-8ac1-ebfdf7c872b8   \n",
       "\n",
       "                                                                                   text  \\\n",
       "02ae95de-7ee3-453a-978d-25d28b3f1a88  Things I want for my business cards but are to...   \n",
       "03f72f70-7a00-4dbb-93b7-6c7f65954fc5  \"If you fight for a cause then fight for a cau...   \n",
       "0aa7bace-924c-40fb-a2e5-3c7012ede244  @username that tweet was mainly for you ;-) ch...   \n",
       "0b66092a-440e-4755-a624-759a580a1c70  @username 'red' and 'blue' and then you wait t...   \n",
       "1094e809-1306-4cd1-8ac1-ebfdf7c872b8  I sit with a boy in english he became my frien...   \n",
       "\n",
       "                                     gender    age  \n",
       "02ae95de-7ee3-453a-978d-25d28b3f1a88      M  25-34  \n",
       "03f72f70-7a00-4dbb-93b7-6c7f65954fc5      M  25-34  \n",
       "0aa7bace-924c-40fb-a2e5-3c7012ede244      M  35-49  \n",
       "0b66092a-440e-4755-a624-759a580a1c70      F  25-34  \n",
       "1094e809-1306-4cd1-8ac1-ebfdf7c872b8      F  18-24  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter2015_truth_df = pd.read_csv(twitter2015_path+os.listdir(twitter2015_path)[-1], sep=\":::\", header=None, names=('file','gender','age','p1','p2','p3','p4','p5'))\n",
    "twitter2015_truth_df = twitter2015_truth_df.set_index('file')\n",
    "twitter2015_df = pd.DataFrame(columns=('file', 'text', 'gender', 'age'))\n",
    "count = 0\n",
    "for file in twitter2015_files:\n",
    "    author = {}\n",
    "    author['file'] = file[:-4]\n",
    "    with open(twitter2015_path+file) as f:\n",
    "        tree = ET.parse(f)\n",
    "        raw_text = []        \n",
    "        for node in tree.iter('document'):\n",
    "            try:\n",
    "                raw_text.append(node.text)\n",
    "            except:\n",
    "                continue\n",
    "            #print raw_text.append(BS(BS(node.text, 'html.parser').get_text().strip(),'html.parser').get_text())            \n",
    "        author['text'] = '\\n'.join(raw_text)\n",
    "       b author['gender'] = twitter2015_truth_df.loc[author['file']]['gender']\n",
    "        #print author['gender']\n",
    "        author['age'] = twitter2015_truth_df.loc[author['file']]['age']\n",
    "    #break\n",
    "    author_series = pd.Series(author)\n",
    "    author_series.name = author['file']\n",
    "    twitter2015_df = twitter2015_df.append(author_series)\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print count, \" records processed\"\n",
    "twitter2015_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e51e1f0ccf130be68b42fdaf201f40e\n",
      "88d1f93972e3c4462b85bc2fa7a9eaae\n",
      "3316270c2e911fc9ee491dbad386ed4e\n",
      "815c739d16821a8df42594567ea83862\n",
      "11a689d54c4af2394bc91b4003e527f3\n",
      "b0d2501202d406fd07ab84db6f751543\n",
      "491f51cc73a8136a66ecfa5349567d08\n",
      "4e100982097898ed43731519079b2624\n",
      "9aa58b658935d017e0827d1b42e75596\n",
      "96f5135be8b958006946821b351a1d80\n",
      "3316270c2e911fc9ee491dbad386ed4e\n",
      "611d21bbf8ba18cfedb76104c117ff76\n",
      "9120e3d36669937b08310ac9b2523550\n",
      "a837091210532f5e37916bba89654b2d\n",
      "066df9d2383e006d1bf69f0e27732988\n",
      "15cf31e89178b2894ea38869d8c6c75e\n",
      "05f97ea55282c4f81fce6fa5751a7ef4\n",
      "f9aaf0e979eda888db209a8f457ce7d7\n",
      "717be9f4b9f1232c9302e3e3eff2239c\n",
      "c4aa5802bf8371620331a83d9de85951\n",
      "153a084dc32a339d356619232f3dea59\n",
      "c297b3ecf103e67237c8a42659a178e3\n",
      "44be30b800f13facaed7cda823976bf1\n",
      "871f9e9590b7102a0c5021ea30f388d2\n",
      "62fce7e595e9d3b9255ba68bc0ca4f67\n",
      "5f29914eb034d37c58a4c06e8eae0bc9\n",
      "ae50c06b7772995439999108e8a94784\n",
      "4687f84cb54bda94350da7f67e51a823\n",
      "6f234b4a1744e80f260f5684433f8598\n",
      "52d582497ed56183efaf715e3988b628\n",
      "7770144c0f68bb53d65893ef9f05c343\n",
      "fd4b49dd6437c1f36958c0dd4abfa400\n",
      "e2e77ba41052044b90d7021d9bff9061\n",
      "01b8aa99619675cae4355aa8af09bd12\n",
      "6300ad90bbcee31349ffa0a071ca2041\n",
      "24620ebc09712f80a6ab85b877693691\n",
      "b10435d02eb67851643ed7acc67f54c0\n",
      "d55a840544dcbdaa40a72afa5ed94e2f\n",
      "2213767ab6ecc93aa98e0d49cfab5baa\n",
      "73d39b8188e8ce968192ca6e993a8f12\n",
      "19a9a1af56559b5d299fae4cbac79a0f\n",
      "db557d7d8315adfe66fa285ee2d5876a\n",
      "515618c30574293240c3b346bdf04b5f\n",
      "7884fd1f622ff26469115316e9daf9eb\n",
      "6c712b47c8e9db4dd7f0f1725045f7bc\n",
      "a959267774764d936d94ee292e992fa0\n",
      "c7a67d7a055820d3239f0e9d89ed8ef0\n",
      "60959f926480ec1e4a3c8c41071779a1\n",
      "d7949c389fdaad77bc556e651095ebce\n",
      "d838b5d5c3cd62b2ad503b53cbc1f90f\n",
      "6c2da2695dc7f933c425842d9a0b364e\n",
      "47fe62a96d93fd6ba25efb25fe7e7069\n",
      "15da7a31e797260960cbf04350085241\n",
      "1e654a67e38ea72384781aa29ebda03e\n",
      "9343a615899a7fbd94403d228463f26d\n",
      "ebfe51690037acec510b6d10d4e58ea5\n",
      "415e74d3bc6d91f2a623c34b596c1703\n",
      "7a9c09bc841cddf568c10203a19bbee8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/bGdt9\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/12YVa7\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.examiner.com/examiner/x-25094-LA-Equine-Policy-Examiner~y2009m12d29-Wild-horse-roundup-gathers-nationwide-protests\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47fe62a96d93fd6ba25efb25fe7e7069\n",
      "fe3e3e680ba647137f5b47fa931072b3\n",
      "a0a70d414e0a11076419e96dfb3c84f4\n",
      "62fce7e595e9d3b9255ba68bc0ca4f67\n",
      "8de2105c1c2af55efadd26c38d57a6d7\n",
      "d865063bfe8c8dd59b4d542b98e028d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.bodalgo.com/voices/yeni-alvarez/index_e.php\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=_jUqe0bYars\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8a8285c8744a9c7f759a69a047437bba\n",
      "8de2105c1c2af55efadd26c38d57a6d7\n",
      "5669fee8a5a0f3379e0bf9821d06b886\n",
      "278578135bfa56ada28f14085db9307b\n",
      "242901098f6f77364668c3a2466a6d01\n",
      "2a51019ad188fecb32cc429c4b4895ed\n",
      "5d37a3f93178969523645e39a0cc8765\n",
      "50  records processed\n",
      "de7ec050322b2cb28f5f138747e937b5\n",
      "957dc24791e83a8f9facd669ebdfab40\n",
      "2d7492af9cb4952640c2a7c7bdfd0510\n",
      "47b9e169b20239e563053af72876a791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://lettersfrom500.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/4UeHaD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/8e0Kel\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/cTSS0l\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/chXSbs\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcd1dd36faf537bc4bbe81f2071f8a0b\n",
      "278578135bfa56ada28f14085db9307b\n",
      "f42e7c6f26cf3e92767b18b9f38db0dc\n",
      "2213767ab6ecc93aa98e0d49cfab5baa\n",
      "8d3d3a9d09bea220b5a99945f57c2910\n",
      "534e590a218b8100bb45208cfbdf163b\n",
      "cb9088be965f6ef60167811b4911d083\n",
      "f19aeb556421957a652607f44cd0618d\n",
      "705094019aa3bee64efd10647d102ecd\n",
      "611d21bbf8ba18cfedb76104c117ff76\n",
      "0cd4619d5395966996a64d0dd25ab76a\n",
      "7eab4a711ed86375a854684f4330ea81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://arstechnica.com/gadgets/news/2010/12/15-phone-3-minutes-all-thats-needed-to-eavesdrop-on-gsm-call.ars\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e475c2e9671ef0fc3f2886df571e89ab\n",
      "4df797da477178b8c07b7f67055fe1b6\n",
      "3832ba1572727deb24c4969ac0b2587d\n",
      "c6d5c510157faec583465dc2f2f7725d\n",
      "1d47415a2fc388ac89b5ecda8a95554c\n",
      "fb5fbb5cef0fd5f64d031b4a39bc4dec\n",
      "cd0da710afd5760211b51fccf55cebc0\n",
      "a8f097700706d240901444bd6bb1813f\n",
      "6e602536dfb72bb2c881fd25e6a92f46\n",
      "fd5b4c852ce49baef7a888198853917c\n",
      "49182c21ede1dd536d3c2f380685c6df\n",
      "9cd9ebf839bf6c5989644b464423cf89\n",
      "ddee9ef7cd0ca20b9fb02c3e0fca4b6c\n",
      "8de2105c1c2af55efadd26c38d57a6d7\n",
      "bcc524d52274108ab6a17810bb2ea695\n",
      "00db29c2dc1d87c8f07b72d753f7f2c0\n",
      "1bf95c355c40496cf62e2edb570ae5de\n",
      "d1ec90379b8333663fec536e79fe29f2\n",
      "f42e7c6f26cf3e92767b18b9f38db0dc\n",
      "b29383409886a8f4525b52eb55c7b2e7\n",
      "aa36a339f30cc056a8137180cdf5d4ef\n",
      "025caf45aaec8db680b23464b930e8bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://ow.ly/1Ceid\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://ow.ly/1Cet8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f7456d58b542c50be788ae5f20326ba\n",
      "60f601460f83a4adac3ee69528bea01c\n",
      "677c3fa6f2bf633912df4f0b8ebf0eee\n",
      "a3e92f89da25918c2092124995357413\n",
      "da115f57c51dfd62696dc17819c89c69\n",
      "6c712b47c8e9db4dd7f0f1725045f7bc\n",
      "b00d4a7efad641297d13e214a80a00c0\n",
      "e475c2e9671ef0fc3f2886df571e89ab\n",
      "146bcb261292b6ae2c3416fdc3ed5c81\n",
      "83ff5fb44444da7a570577d8cca44cb9\n",
      "89e28784c0c0c2236124a934f54c4e04\n",
      "a1b53e143dcf8699338077548906cb4b\n",
      "3b05acf07f6f03715ab66eaf2a3b5d04\n",
      "1110e5330c38f208b2887f55f7296235\n",
      "f97b2cf731bc770023edc37b30c95edd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://twitgoo.com/9vv8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.facebook.com/photo.php?pid=210061&amp;l=1710e9d3d3&amp;id=128476260507099\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.facebook.com/photo.php?pid=210128&amp;l=06d6cfb8f8&amp;id=128476260507099\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.facebook.com/photo.php?pid=210129&amp;l=5b87c752e8&amp;id=128476260507099\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebfe51690037acec510b6d10d4e58ea5\n",
      "fd5b4c852ce49baef7a888198853917c\n",
      "833f9711a4e415b8398c8ddffbeac33d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://ohmythatsawesome.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://tinyurl.com/dgswcd\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b4f536c8c69f0fa770a87a84df93ff00\n",
      "0a9e35fd6f123137d585a482f2484d8e\n",
      "4687f84cb54bda94350da7f67e51a823\n",
      "4392ce5936db3591f713b0171ffd0e17\n",
      "100  records processed\n",
      "82afe6d0e442474805f60abaae33b16d\n",
      "c0c92b0debe3dc52396f9441d3b7bd4d\n",
      "ddd2f9d10aab42acefcfb55ca5572bf7\n",
      "b040812b4f65cc449ec54699ac764181\n",
      "9343a615899a7fbd94403d228463f26d\n",
      "4e100982097898ed43731519079b2624\n",
      "1d5c9e2c52e7810c9d4bab6a1ed0d73f\n",
      "30d04c264517f10e8bc1ff1fa85cc171\n",
      "1d47415a2fc388ac89b5ecda8a95554c\n",
      "20bf285bfb69897524b8c444a8ca197d\n",
      "9286dd073b9ef429c97ba2426f626f3c\n",
      "85682013120aee589c5a11b83233ae44\n",
      "fa294b42e0f15881bbb29812b5f51be8\n",
      "46bce687f790f4688a582da097b604ef\n",
      "b0d2501202d406fd07ab84db6f751543\n",
      "5f29914eb034d37c58a4c06e8eae0bc9\n",
      "95290012090969ed4e58ab1a9ff6c342\n",
      "98235f2c239b119c166a549b19b52abf\n",
      "f09f1914be5fb34479264b1117b41508\n",
      "52bf2acfb0403cd5557d7b77a4de93f8\n",
      "ba60ddef7a784f9d15793b264e107098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://tinyurl.com/5cear3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://tinyurl.com/5kvzhc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5041977a41240fa87c06e5d98500921a\n",
      "1110e5330c38f208b2887f55f7296235\n",
      "6df62259a7da8075617a9ff97bb265c1\n",
      "674e327673e224ce6f2c3bee658ac14a\n",
      "4de662e0e342a9ded396c7415de91a56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.botanicalls.com/twitter/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15da7a31e797260960cbf04350085241\n",
      "8de2105c1c2af55efadd26c38d57a6d7\n",
      "9286dd073b9ef429c97ba2426f626f3c\n",
      "b29383409886a8f4525b52eb55c7b2e7\n",
      "6b529117cf7016c19396748c42a0f874\n",
      "7ef4b07863703ef906a27c6cc1ef2cf1\n",
      "9f5ffb7a6a0173156193d52d831eaacf\n",
      "22c11b9f7e8e94f3d11bdcda976bbc63\n",
      "bca317bab408efbfb850aaf055948e47\n",
      "ddd2f9d10aab42acefcfb55ca5572bf7\n",
      "d9ee6cc0a5712fbe4c4d06465ab5b939\n",
      "677c3fa6f2bf633912df4f0b8ebf0eee\n",
      "ebe3d72e3e5ee4a2bb39ebe437ad1235\n",
      "75470794aa1249218c8d5699018560ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://news.yahoo.com/s/livescience/20100625/sc_livescience/darksideofmedicalresearchwidespreadbiasandomissions\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://healthland.time.com/2010/09/23/study-america-is-officially-the-fattest-developed-country-in-the-world/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.hsph.harvard.edu/nutritionsource/what-should-you-eat/calcium-and-milk/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4aa5802bf8371620331a83d9de85951\n",
      "696b5f0612f4c6249b28c0ea69bb5705\n",
      "4a9c6df0b335c37ef60611c592c3d154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://20somethingfinance.com/pay-off-student-loan-debt-or-save-for-retirement/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c330c997feb912afba713bad6bba2dcb\n",
      "6c712b47c8e9db4dd7f0f1725045f7bc\n",
      "115e7b931be3d52d35cb8ce2da09a1d7\n",
      "a28f8dd03948a47b1144ad5df6ccc483\n",
      "36b2593435e1bed13eb138c1973c13ed\n",
      "8de2105c1c2af55efadd26c38d57a6d7\n",
      "dd066409a86e37f7ba41ed32fad5fed9\n",
      "6d5873bedcf09d9753c3c908ddf452af\n",
      "ca59762fccbeb8a73f349c99a256a220\n",
      "9354e4ff65d876fbf0bc17ac650c7054\n",
      "f18213b41bb7311717493a931dc32296\n",
      "b4b03d72bcf52773ec6b7c0a91ccfe1e\n",
      "75470794aa1249218c8d5699018560ab\n",
      "f677a164b16096fc2eb3af86694da8ac\n",
      "c14f5f6eb08d47b72bc8dae3187aad75\n",
      "361a5b6f327d74344f0f8c4cd7c27970\n",
      "fd5b4c852ce49baef7a888198853917c\n",
      "150  records processed\n",
      "f5abf96f244c876d17ecf69863cb0abb\n",
      "61244154e362cece7e2d3c1139948bde\n",
      "d3fbad0a96845119d5dbd0e772c9fe53\n",
      "ac9bec22ac3b5c33abd7299845283f9f\n",
      "3de105c51ab70cbf61df2b36fb5a0fd4\n",
      "3373639b1d50d755c03c02cd9b93b720\n",
      "9c66f13c8038d9cec5fd2a754d959c2f\n",
      "b00d4a7efad641297d13e214a80a00c0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bit.ly/1Jbam\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40b8af7721fd105d0f5ecb5dad74a991\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1e51e1f0ccf130be68b42fdaf201f40e</th>\n",
       "      <td>1e51e1f0ccf130be68b42fdaf201f40e</td>\n",
       "      <td>More great coverage of the #divestment campaig...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>25-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88d1f93972e3c4462b85bc2fa7a9eaae</th>\n",
       "      <td>88d1f93972e3c4462b85bc2fa7a9eaae</td>\n",
       "      <td>@TomNixonSpeaks, sign up for Klout and see how...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>50-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316270c2e911fc9ee491dbad386ed4e</th>\n",
       "      <td>3316270c2e911fc9ee491dbad386ed4e</td>\n",
       "      <td>Problemtica del Analista es a Cul Jugador Re...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>65-xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815c739d16821a8df42594567ea83862</th>\n",
       "      <td>815c739d16821a8df42594567ea83862</td>\n",
       "      <td>Nueva imagen de Batman vs Deathstroke en el v...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11a689d54c4af2394bc91b4003e527f3</th>\n",
       "      <td>11a689d54c4af2394bc91b4003e527f3</td>\n",
       "      <td>If you've been involved in an auto accident, y...</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              file  \\\n",
       "1e51e1f0ccf130be68b42fdaf201f40e  1e51e1f0ccf130be68b42fdaf201f40e   \n",
       "88d1f93972e3c4462b85bc2fa7a9eaae  88d1f93972e3c4462b85bc2fa7a9eaae   \n",
       "3316270c2e911fc9ee491dbad386ed4e  3316270c2e911fc9ee491dbad386ed4e   \n",
       "815c739d16821a8df42594567ea83862  815c739d16821a8df42594567ea83862   \n",
       "11a689d54c4af2394bc91b4003e527f3  11a689d54c4af2394bc91b4003e527f3   \n",
       "\n",
       "                                                                               text  \\\n",
       "1e51e1f0ccf130be68b42fdaf201f40e  More great coverage of the #divestment campaig...   \n",
       "88d1f93972e3c4462b85bc2fa7a9eaae  @TomNixonSpeaks, sign up for Klout and see how...   \n",
       "3316270c2e911fc9ee491dbad386ed4e  Problemtica del Analista es a Cul Jugador Re...   \n",
       "815c739d16821a8df42594567ea83862  Nueva imagen de Batman vs Deathstroke en el v...   \n",
       "11a689d54c4af2394bc91b4003e527f3  If you've been involved in an auto accident, y...   \n",
       "\n",
       "                                 gender    age  \n",
       "1e51e1f0ccf130be68b42fdaf201f40e   MALE  25-34  \n",
       "88d1f93972e3c4462b85bc2fa7a9eaae   MALE  50-64  \n",
       "3316270c2e911fc9ee491dbad386ed4e   MALE  65-xx  \n",
       "815c739d16821a8df42594567ea83862   MALE  35-49  \n",
       "11a689d54c4af2394bc91b4003e527f3   MALE  35-49  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter2016_truth_df = pd.read_csv(twitter2016_path+os.listdir(twitter2016_path)[-1], sep=\":::\", header=None, names=('file','gender','age'))\n",
    "twitter2016_truth_df = twitter2016_truth_df.set_index('file')\n",
    "twitter2016_df = pd.DataFrame(columns=('file', 'text', 'gender', 'age'))\n",
    "count = 0\n",
    "# print twitter2016_files\n",
    "for file in twitter2016_files:\n",
    "    author = {}\n",
    "    author['file'] = file[:-4]\n",
    "#     print author['file']\n",
    "    with open(twitter2016_path+file) as f:\n",
    "        try:\n",
    "            tree = ET.parse(f)\n",
    "            raw_text = []        \n",
    "            for node in tree.iter('document'):\n",
    "                raw_text.append(BS(node.text, 'html.parser').get_text().strip())\n",
    "        except:\n",
    "            continue\n",
    "        author['text'] = '\\n'.join(raw_text)\n",
    "        author['gender'] = twitter2016_truth_df.loc[author['file']]['gender']\n",
    "#         print author['text']\n",
    "        author['age'] = twitter2016_truth_df.loc[author['file']]['age']\n",
    "#     break\n",
    "    author_series = pd.Series(author)\n",
    "    author_series.name = author['file']\n",
    "    twitter2016_df = twitter2016_df.append(author_series)\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print count, \" records processed\"\n",
    "twitter2016_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
